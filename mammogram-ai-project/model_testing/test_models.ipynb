{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Visualisation\n",
    "\n",
    "This notebook evaluates the performance of each trained model on the test set. For each model, it:\n",
    "\n",
    "- Computes and displays the confusion matrix, AUC-ROC curve, and precision-recall curve.\n",
    "- Provides key metrics such as accuracy, recall, precision, and F1-score.\n",
    "- Generates sample Grad-CAM heatmaps to visually interpret the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, ConcatDataset, Subset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc as calc_auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import colormaps\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image_rgb = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image_rgb = self.transform(image_rgb)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image_rgb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform  = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped calcification data\n",
    "calc_test_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Test-png-cropped/labels/calc-test_labels.csv\"\n",
    "calc_test_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Test-png-cropped/images\"\n",
    "\n",
    "# now apply the transformations to the calcification images\n",
    "calc_test_data = CustomImageDataset(calc_test_label_dir, calc_test_img_dir, test_transform)\n",
    "\n",
    "# cropped mass data\n",
    "mass_test_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Test-png-cropped/labels/mass-test_labels.csv\"\n",
    "mass_test_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Test-png-cropped/images\"\n",
    "\n",
    "# now apply the transformations to the mass images\n",
    "mass_test_data = CustomImageDataset(mass_test_label_dir, mass_test_img_dir, test_transform)\n",
    "\n",
    "# Merge test datasets\n",
    "combined_test_data = ConcatDataset([calc_test_data, mass_test_data])\n",
    "\n",
    "test_indices = np.random.permutation(len(combined_test_data))\n",
    "\n",
    "shuffled_test_data = Subset(combined_test_data, test_indices)\n",
    "\n",
    "print(f\"Total testing samples: {len(shuffled_test_data)}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "num_workers = 0\n",
    "\n",
    "test_dataloader = DataLoader(shuffled_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"Benign\",\n",
    "    1: \"Malignant\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(shuffled_test_data), size=(1,)).item()\n",
    "    img, label = shuffled_test_data[sample_idx]\n",
    "\n",
    "    image_np = np.array(img)\n",
    "    print(image_np.shape)\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    if(torch.is_tensor(img)):\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unnormalize images\n",
    "def unnormalise(img_tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Reverses ImageNet normalisation to recover original image values.\n",
    "    \"\"\"\n",
    "    mean = torch.tensor(mean).view(3, 1, 1)\n",
    "    std = torch.tensor(std).view(3, 1, 1)\n",
    "    return img_tensor * std + mean  # Reverse normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables for Grad-CAM\n",
    "gradients = None\n",
    "activations = None\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output\n",
    "\n",
    "def forward_hook(module, args, output):\n",
    "    global activations\n",
    "    activations = output \n",
    "\n",
    "def generate_gradcam(model, image):\n",
    "    \"\"\"\n",
    "    Generates Grad-CAM heatmap for a given image.\n",
    "    \"\"\"\n",
    "    global gradients, activations\n",
    "    \n",
    "    model.zero_grad()\n",
    "    output = model(image)\n",
    "    prob = output.sigmoid()\n",
    "    pred_label = (prob > 0.5).float()\n",
    "    \n",
    "    # Backward pass to get gradients\n",
    "    output.backward(torch.ones_like(output))  \n",
    "    \n",
    "    # Pool gradients across the channels\n",
    "    pooled_gradients = torch.mean(gradients[0], dim=[0, 2, 3])\n",
    "\n",
    "    # Weight the channels by corresponding gradients\n",
    "    for i in range(activations.size()[1]):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    # Compute heatmap\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = F.relu(heatmap)\n",
    "    heatmap /= torch.max(heatmap)\n",
    "\n",
    "    return heatmap.detach().cpu()\n",
    "\n",
    "def overlay_heatmap(img_tensor, heatmap):\n",
    "    \"\"\"\n",
    "    Overlays the Grad-CAM heatmap on the original image.\n",
    "    \"\"\"\n",
    "    unnorm_img = unnormalise(img_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    original_img = to_pil_image(unnorm_img.clamp(0, 1), mode='RGB')\n",
    "\n",
    "    # Resize the heatmap to match image size\n",
    "    overlay = to_pil_image(heatmap, mode='F').resize((224, 224), resample=PIL.Image.BICUBIC)\n",
    "\n",
    "    # Apply colormap\n",
    "    cmap = colormaps['jet']\n",
    "    overlay = (255 * cmap(np.asarray(overlay) ** 2)[:, :, :3]).astype(np.uint8)\n",
    "\n",
    "    return original_img, overlay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_test(dataloader, model, model_code, num_rows=2):\n",
    "    print(\"\\nEvaluating on Test Set...\")\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    sample_images = []\n",
    "    sample_heatmaps = []\n",
    "    sample_labels = []\n",
    "    sample_preds = []\n",
    "    sample_confidences = []\n",
    "\n",
    "    num_examples = num_rows * 5\n",
    "    \n",
    "    # Identify the last convolutional layer\n",
    "    if model_code == \"densenet121\":\n",
    "        last_conv_layer = model.features.denseblock4.denselayer16.conv2\n",
    "    elif model_code == \"densenet169\":\n",
    "        last_conv_layer = model.features.denseblock4.denselayer32.conv2\n",
    "    elif model_code == \"mobilenet_v3\":\n",
    "        last_conv_layer = model.features[-1]\n",
    "    elif model_code == \"efficientnet\":\n",
    "        last_conv_layer = model.features[-1][0]\n",
    "        \n",
    "    # Register hooks for Grad-CAM\n",
    "    last_conv_layer.register_full_backward_hook(backward_hook)\n",
    "    last_conv_layer.register_forward_hook(forward_hook)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, desc=\"Testing\", total=num_batches, leave=True):\n",
    "            X, y = X.to(device), y.to(device).view(-1, 1).float()\n",
    "            pred = model(X)\n",
    "            prob = pred.sigmoid()\n",
    "            pred_labels = (prob > 0.5).float()\n",
    "\n",
    "            correct += (pred_labels == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_preds.extend(pred_labels.cpu().numpy())\n",
    "            all_probs.extend(prob.cpu().numpy())\n",
    "\n",
    "            # Store sample images and Grad-CAM visualisations\n",
    "            if len(sample_images) < num_examples:\n",
    "                for i in range(min(num_examples - len(sample_images), X.shape[0])): \n",
    "                    img_tensor = X[i].cpu()\n",
    "                    # Enable gradients only for Grad-CAM\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        heatmap = generate_gradcam(model, X[i].unsqueeze(0))\n",
    "\n",
    "                    original_img, overlay_img = overlay_heatmap(img_tensor, heatmap)\n",
    "\n",
    "                    sample_images.append(original_img)\n",
    "                    sample_heatmaps.append(overlay_img)\n",
    "                    sample_labels.append(int(y[i].cpu().item()))\n",
    "                    sample_preds.append(int(pred_labels[i].cpu().item()))\n",
    "\n",
    "                    # Compute adjusted confidence score\n",
    "                    prob_value = prob[i].cpu().item()\n",
    "                    if pred_labels[i] == 1:\n",
    "                        confidence = (prob_value - 0.5) * 200\n",
    "                    else:\n",
    "                        confidence = (0.5 - prob_value) * 200\n",
    "\n",
    "                    sample_confidences.append(confidence)\n",
    "\n",
    "    # Compute final metrics\n",
    "    accuracy = correct / total * 100\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC: {auc:.3f}\")\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Benign\", \"Malignant\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Compute ROC Curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = calc_auc(fpr, tpr)\n",
    "\n",
    "    # Compute Precision-Recall Curve and Average Precision\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(all_labels, all_probs)\n",
    "    avg_precision = average_precision_score(all_labels, all_probs)\n",
    "\n",
    "    # Plot side-by-side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # ROC Curve\n",
    "    axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title('ROC Curve')\n",
    "    axes[0].legend(loc='lower right')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    axes[1].plot(recall_vals, precision_vals, color='green', lw=2, label=f'AP = {avg_precision:.2f}')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('Recall')\n",
    "    axes[1].set_ylabel('Precision')\n",
    "    axes[1].set_title('Precision-Recall Curve')\n",
    "    axes[1].legend(loc='lower left')\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Plot original images and Grad-CAM heatmaps\n",
    "    fig, axes = plt.subplots(num_rows * 2, 5, figsize=(15, 6 * num_rows))\n",
    "    fig.suptitle(\"Sample Predictions with Grad-CAM\", fontsize=16)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        row = (i // 5) * 2\n",
    "        col = i % 5\n",
    "\n",
    "        # Plot original image\n",
    "        axes[row, col].imshow(sample_images[i], cmap=\"gray\")\n",
    "        true_label = \"Malignant\" if sample_labels[i] == 1 else \"Benign\"\n",
    "        pred_label = \"Malignant\" if sample_preds[i] == 1 else \"Benign\"\n",
    "        confidence = sample_confidences[i]\n",
    "\n",
    "        axes[row, col].set_title(f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%\")\n",
    "        axes[row, col].axis(\"off\")\n",
    "\n",
    "        # Plot Grad-CAM heatmap\n",
    "        axes[row + 1, col].imshow(sample_images[i], cmap=\"gray\")\n",
    "        axes[row + 1, col].imshow(sample_heatmaps[i], alpha=0.4, interpolation=\"nearest\")\n",
    "        axes[row + 1, col].set_title(\"Grad-CAM\")\n",
    "        axes[row + 1, col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MPS Available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS Built:\", torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable MPS if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121\n",
    "\n",
    "# Load the best model state\n",
    "model_d121_path = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/webapp/static/models/best_model_run13.pth\"\n",
    "\n",
    "model_d121 = densenet121(weights=None)\n",
    "# Modify the classifier for binary classification\n",
    "model_d121.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1024, out_features=1) \n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model_d121 = model_d121.to(device)\n",
    "\n",
    "model_d121.load_state_dict(torch.load(model_d121_path, map_location=torch.device('cpu')))\n",
    "model_d121.eval()\n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = final_test(test_dataloader, model_d121, model_code=\"densenet121\", num_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet169\n",
    "\n",
    "# Load the best model state\n",
    "model_d169_path = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/webapp/static/models/best_model_run25.pth\"\n",
    "\n",
    "model_d169 = densenet169(weights=None)\n",
    "# Modify the classifier for binary classification\n",
    "model_d169.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=1664, out_features=1)\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model_d169 = model_d169.to(device)\n",
    "\n",
    "model_d169.load_state_dict(torch.load(model_d169_path, map_location=torch.device('cpu')))\n",
    "model_d169.eval()\n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = final_test(test_dataloader, model_d169, model_code=\"densenet169\", num_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_small\n",
    "\n",
    "# Load the best model state\n",
    "model_mns_path = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/webapp/static/models/best_model_run15.pth\"\n",
    "\n",
    "model_mns = mobilenet_v3_small(weights=None)  # Initialize the model\n",
    "# Check the number of input features for the classifier\n",
    "num_features = model_mns.classifier[0].in_features\n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "model_mns.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5), #add 50% Dropout\n",
    "    nn.Linear(num_features, 1)\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model_mns = model_mns.to(device)\n",
    "\n",
    "model_mns.load_state_dict(torch.load(model_mns_path, map_location=torch.device('cpu')))\n",
    "model_mns.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = final_test(test_dataloader, model_mns, model_code=\"mobilenet_v3\", num_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v3_large\n",
    "\n",
    "# Load the best model state\n",
    "model_mnl_path = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/webapp/static/models/best_model_run39.pth\"\n",
    "\n",
    "model_mnl = mobilenet_v3_large(weights=None)\n",
    "# Check the number of input features for the classifier\n",
    "num_features = model_mnl.classifier[0].in_features\n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "model_mnl.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(num_features, 1)\n",
    ")\n",
    "\n",
    "\n",
    "# Move model to GPU if available\n",
    "model_mnl = model_mnl.to(device)\n",
    "\n",
    "model_mnl.load_state_dict(torch.load(model_mnl_path, map_location=torch.device('cpu')))\n",
    "model_mnl.eval()\n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = final_test(test_dataloader, model_mnl, model_code=\"mobilenet_v3\", num_rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "# Load the best model state\n",
    "model_eb0_path = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/webapp/static/models/best_model_run20.pth\"\n",
    "\n",
    "model_eb0 = efficientnet_b0(weights=None) \n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "model_eb0.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1280, out_features=1)\n",
    ")\n",
    "\n",
    "model_eb0 = model_eb0.to(device)\n",
    "\n",
    "model_eb0.load_state_dict(torch.load(model_eb0_path, map_location=torch.device('cpu')))\n",
    "model_eb0.eval() \n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = final_test(test_dataloader, model_eb0, model_code=\"efficientnet\", num_rows=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
