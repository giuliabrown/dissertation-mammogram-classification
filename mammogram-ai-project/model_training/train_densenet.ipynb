{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet-169 and DenseNet-121 Training\n",
    "\n",
    "This notebook trains two convolutional neural network architectures, **DenseNet-169** and **DenseNet-121**, for binary classification of mammograms (benign vs malignant).\n",
    "\n",
    "The training was performed on **Kaggle** using GPU acceleration.  \n",
    "If you wish to run this notebook locally, you may need to modify some directory paths (e.g., for data loading, model saving, and output locations) to match your machine's folder structure.\n",
    "\n",
    "Key components of this notebook include:\n",
    "- Loading and preprocessing the training and validation datasets\n",
    "- Applying data augmentation to improve model generalisation\n",
    "- Fine-tuning DenseNet-169 and DenseNet-121 models pre-trained on ImageNet\n",
    "- Tracking training and validation performance over epochs\n",
    "- Saving the best-performing model checkpoints based on accuracy and validation AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:18:31.263131Z",
     "iopub.status.busy": "2025-03-27T07:18:31.262812Z",
     "iopub.status.idle": "2025-03-27T07:18:37.904026Z",
     "shell.execute_reply": "2025-03-27T07:18:37.903352Z",
     "shell.execute_reply.started": "2025-03-27T07:18:31.263077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, random_split, ConcatDataset, Subset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import colormaps\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:18:41.142540Z",
     "iopub.status.busy": "2025-03-27T07:18:41.142028Z",
     "iopub.status.idle": "2025-03-27T07:18:41.147973Z",
     "shell.execute_reply": "2025-03-27T07:18:41.147233Z",
     "shell.execute_reply.started": "2025-03-27T07:18:41.142511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image_rgb = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image_rgb = self.transform(image_rgb)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image_rgb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:18:46.914286Z",
     "iopub.status.busy": "2025-03-27T07:18:46.913954Z",
     "iopub.status.idle": "2025-03-27T07:18:46.919567Z",
     "shell.execute_reply": "2025-03-27T07:18:46.918697Z",
     "shell.execute_reply.started": "2025-03-27T07:18:46.914258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to add Gaussian noise\n",
    "class AddGaussianNoise(torch.nn.Module):\n",
    "    def __init__(self, mean=0.0, std=0.05, p=0.3):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        if random.random() < self.p:  # Apply noise with probability p\n",
    "            noise = torch.randn_like(tensor) * self.std\n",
    "            tensor = torch.clamp(tensor + noise, 0, 1)  # Keep values in [0,1]\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:18:47.244504Z",
     "iopub.status.busy": "2025-03-27T07:18:47.244194Z",
     "iopub.status.idle": "2025-03-27T07:18:47.249543Z",
     "shell.execute_reply": "2025-03-27T07:18:47.248773Z",
     "shell.execute_reply.started": "2025-03-27T07:18:47.244479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom CLAHE Transform\n",
    "class ApplyCLAHE:\n",
    "    def __init__(self, clip_limit=5.0, tile_grid_size=(8,8), p=1.0):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "        self.p = p  # Probability of applying CLAHE\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:  # Apply CLAHE with probability p\n",
    "            img_np = np.array(img)  # Convert PIL to NumPy\n",
    "            img_gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            img_clahe = clahe.apply(img_gray)\n",
    "\n",
    "            # Convert back to 3-channel grayscale (DenseNet expects 3 channels)\n",
    "            img_clahe = cv2.merge([img_clahe, img_clahe, img_clahe])\n",
    "            return Image.fromarray(img_clahe)  # Convert back to PIL\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:20.772255Z",
     "iopub.status.busy": "2025-03-27T07:55:20.771880Z",
     "iopub.status.idle": "2025-03-27T07:55:20.777871Z",
     "shell.execute_reply": "2025-03-27T07:55:20.776973Z",
     "shell.execute_reply.started": "2025-03-27T07:55:20.772221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define transformations to apply to the images (for ImageNet weights)\n",
    "train_transform  = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    #ApplyCLAHE(clip_limit=5.0, tile_grid_size=(8,8), p=1.0),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    T.ToTensor(),\n",
    "    AddGaussianNoise(std=0.05, p=0.3),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform  = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    #ApplyCLAHE(clip_limit=5.0, tile_grid_size=(8,8), p=1.0), \n",
    "    T.ToTensor(), \n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:23.858852Z",
     "iopub.status.busy": "2025-03-27T07:55:23.858571Z",
     "iopub.status.idle": "2025-03-27T07:55:23.888855Z",
     "shell.execute_reply": "2025-03-27T07:55:23.888183Z",
     "shell.execute_reply.started": "2025-03-27T07:55:23.858829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define paths to cropped calcification data\n",
    "calc_train_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Training-png-cropped/labels/calc-train_labels.csv\"\n",
    "calc_test_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Test-png-cropped/labels/calc-test_labels.csv\"\n",
    "\n",
    "calc_train_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Training-png-cropped/images\"\n",
    "calc_test_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Test-png-cropped/images\"\n",
    "\n",
    "# Apply the transformations to the calcification images\n",
    "calc_training_data = CustomImageDataset(calc_train_label_dir, calc_train_img_dir, train_transform)\n",
    "calc_test_data = CustomImageDataset(calc_test_label_dir, calc_test_img_dir, test_transform)\n",
    "\n",
    "# Define paths to cropped mass data\n",
    "mass_train_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Training-png-cropped/labels/mass-train_labels.csv\"\n",
    "mass_test_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Test-png-cropped/labels/mass-test_labels.csv\"\n",
    "\n",
    "mass_train_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Training-png-cropped/images\"\n",
    "mass_test_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Test-png-cropped/images\"\n",
    "\n",
    "# Apply the transformations to the mass images\n",
    "mass_training_data = CustomImageDataset(mass_train_label_dir, mass_train_img_dir, train_transform)\n",
    "mass_test_data = CustomImageDataset(mass_test_label_dir, mass_test_img_dir, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:24.236998Z",
     "iopub.status.busy": "2025-03-27T07:55:24.236694Z",
     "iopub.status.idle": "2025-03-27T07:55:24.240812Z",
     "shell.execute_reply": "2025-03-27T07:55:24.239967Z",
     "shell.execute_reply.started": "2025-03-27T07:55:24.236975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Merge training datasets\n",
    "combined_train_data = ConcatDataset([calc_training_data, mass_training_data])\n",
    "\n",
    "# Merge test datasets\n",
    "combined_test_data = ConcatDataset([calc_test_data, mass_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:24.555863Z",
     "iopub.status.busy": "2025-03-27T07:55:24.555574Z",
     "iopub.status.idle": "2025-03-27T07:55:24.563878Z",
     "shell.execute_reply": "2025-03-27T07:55:24.563226Z",
     "shell.execute_reply.started": "2025-03-27T07:55:24.555839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split training data into train and validation (maintaining the labels balanced in both datasets)\n",
    "# Define validation split sizes (80% train, 20% validation)\n",
    "val_size = 0.2\n",
    "\n",
    "# Extract labels\n",
    "labels = []\n",
    "for dataset in combined_train_data.datasets:\n",
    "    labels.extend(dataset.img_labels.iloc[:, 2].tolist())\n",
    "\n",
    "# Perform stratified split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(combined_train_data)), \n",
    "    test_size = val_size, \n",
    "    stratify = labels,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(combined_train_data, train_idx)\n",
    "val_dataset = Subset(combined_train_data, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:25.317446Z",
     "iopub.status.busy": "2025-03-27T07:55:25.317072Z",
     "iopub.status.idle": "2025-03-27T07:55:25.321712Z",
     "shell.execute_reply": "2025-03-27T07:55:25.320703Z",
     "shell.execute_reply.started": "2025-03-27T07:55:25.317419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# shuffle validation and testing datasets once before creating the dataloaders\n",
    "# Create shuffled indices\n",
    "val_indices = np.random.permutation(len(val_dataset))\n",
    "test_indices = np.random.permutation(len(combined_test_data))\n",
    "\n",
    "# Apply shuffled indices to dataset\n",
    "shuffled_val_data = Subset(val_dataset, val_indices)\n",
    "shuffled_test_data = Subset(combined_test_data, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:28.588621Z",
     "iopub.status.busy": "2025-03-27T07:55:28.588339Z",
     "iopub.status.idle": "2025-03-27T07:55:28.593725Z",
     "shell.execute_reply": "2025-03-27T07:55:28.592808Z",
     "shell.execute_reply.started": "2025-03-27T07:55:28.588599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1953\n",
      "Validation samples: 489\n",
      "Total testing samples: 639\n"
     ]
    }
   ],
   "source": [
    "# Check dataset sizes\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(shuffled_val_data)}\")\n",
    "print(f\"Total testing samples: {len(shuffled_test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:29.163055Z",
     "iopub.status.busy": "2025-03-27T07:55:29.162599Z",
     "iopub.status.idle": "2025-03-27T07:55:29.167834Z",
     "shell.execute_reply": "2025-03-27T07:55:29.167130Z",
     "shell.execute_reply.started": "2025-03-27T07:55:29.163017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "num_workers = 4\n",
    "\n",
    "# shuffle = True\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "# shuffle = False, so that the batches don't change every epoch, making it easier to compare results\n",
    "val_dataloader = DataLoader(shuffled_val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(shuffled_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:30.777048Z",
     "iopub.status.busy": "2025-03-27T07:55:30.776757Z",
     "iopub.status.idle": "2025-03-27T07:55:32.981132Z",
     "shell.execute_reply": "2025-03-27T07:55:32.980160Z",
     "shell.execute_reply.started": "2025-03-27T07:55:30.777026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"Benign\",\n",
    "    1: \"Malignant\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    #print(img.shape)\n",
    "\n",
    "    image_np = np.array(img)  # Convert to NumPy array\n",
    "    print(image_np.shape)\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    #plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    if(torch.is_tensor(img)):\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:37.578068Z",
     "iopub.status.busy": "2025-03-27T07:55:37.577733Z",
     "iopub.status.idle": "2025-03-27T07:55:37.585260Z",
     "shell.execute_reply": "2025-03-27T07:55:37.584332Z",
     "shell.execute_reply.started": "2025-03-27T07:55:37.578039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0  # To accumulate the loss in each batch\n",
    "    correct_predictions = 0  # To accumulate the number of correct predictions\n",
    "\n",
    "    for batch, (X, y) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\", leave=True):\n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True).view(-1, 1).float()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item() \n",
    "\n",
    "        # Calculate accuracy\n",
    "        pred_labels = (pred.sigmoid() > 0.5).float()\n",
    "        correct_predictions += (pred_labels == y).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Calculate overall training accuracy\n",
    "    epoch_accuracy = correct_predictions / size * 100\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)  # Average loss for the epoch\n",
    "    print(f\"Epoch Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:39.052840Z",
     "iopub.status.busy": "2025-03-27T07:55:39.052535Z",
     "iopub.status.idle": "2025-03-27T07:55:39.059565Z",
     "shell.execute_reply": "2025-03-27T07:55:39.058650Z",
     "shell.execute_reply.started": "2025-03-27T07:55:39.052815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "def val(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, desc=\"Testing\", total=num_batches, leave=True):\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True).view(-1, 1).float()\n",
    "            pred = model(X)\n",
    "            prob = pred.sigmoid()  # Convert logits to probabilities\n",
    "            pred_labels = (prob > 0.5).float()  # Convert probabilities to binary labels\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred_labels == y).sum().item()\n",
    "            \n",
    "            all_labels.extend(y.cpu().numpy())  # Collect true labels\n",
    "            all_preds.extend(pred_labels.cpu().numpy())  # Collect predicted labels\n",
    "            all_probs.extend(prob.cpu().numpy())  # Collect predicted probabilities\n",
    "\n",
    "    # Compute overall statistics\n",
    "    test_loss /= num_batches\n",
    "    accuracy = correct / size * 100\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {accuracy:.1f}%, Avg loss: {test_loss:.6f}\")\n",
    "    print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC: {auc:.3f}\\n\")\n",
    "\n",
    "    return test_loss, accuracy, precision, recall, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:45.077471Z",
     "iopub.status.busy": "2025-03-27T07:55:45.077189Z",
     "iopub.status.idle": "2025-03-27T07:55:45.085465Z",
     "shell.execute_reply": "2025-03-27T07:55:45.084610Z",
     "shell.execute_reply.started": "2025-03-27T07:55:45.077451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define global variables for Grad-CAM\n",
    "gradients = None\n",
    "activations = None\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output\n",
    "\n",
    "def forward_hook(module, args, output):\n",
    "    global activations\n",
    "    activations = output\n",
    "\n",
    "def generate_gradcam(model, image):\n",
    "    \"\"\"\n",
    "    Generates Grad-CAM heatmap for a given image.\n",
    "    \"\"\"\n",
    "    global gradients, activations\n",
    "    \n",
    "    model.zero_grad()\n",
    "    output = model(image)\n",
    "    prob = output.sigmoid()\n",
    "    pred_label = (prob > 0.5).float()\n",
    "    \n",
    "    # Backward pass to get gradients\n",
    "    output.backward(torch.ones_like(output))  \n",
    "    \n",
    "    # Pool gradients across the channels\n",
    "    pooled_gradients = torch.mean(gradients[0], dim=[0, 2, 3])\n",
    "\n",
    "    # Weight the channels by corresponding gradients\n",
    "    for i in range(activations.size()[1]):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    # Compute heatmap\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = F.relu(heatmap)\n",
    "    heatmap /= torch.max(heatmap)\n",
    "\n",
    "    return heatmap.detach().cpu()\n",
    "\n",
    "def overlay_heatmap(img_tensor, heatmap):\n",
    "    \"\"\"\n",
    "    Overlays the Grad-CAM heatmap on the original image.\n",
    "    \"\"\"\n",
    "\n",
    "    unnorm_img = unnormalize(img_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    original_img = to_pil_image(unnorm_img.clamp(0, 1), mode='RGB')\n",
    "\n",
    "    # Resize the heatmap to match image size\n",
    "    overlay = to_pil_image(heatmap, mode='F').resize((224, 224), resample=PIL.Image.BICUBIC)\n",
    "\n",
    "    # Apply colormap\n",
    "    cmap = colormaps['jet']\n",
    "    overlay = (255 * cmap(np.asarray(overlay) ** 2)[:, :, :3]).astype(np.uint8)\n",
    "\n",
    "    return original_img, overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:46.459900Z",
     "iopub.status.busy": "2025-03-27T07:55:46.459615Z",
     "iopub.status.idle": "2025-03-27T07:55:46.464155Z",
     "shell.execute_reply": "2025-03-27T07:55:46.463316Z",
     "shell.execute_reply.started": "2025-03-27T07:55:46.459877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to unnormalise images\n",
    "def unnormalise(img_tensor, mean, std):\n",
    "    mean = torch.tensor(mean).view(3, 1, 1)\n",
    "    std = torch.tensor(std).view(3, 1, 1)\n",
    "    return img_tensor * std + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:47.364633Z",
     "iopub.status.busy": "2025-03-27T07:55:47.364344Z",
     "iopub.status.idle": "2025-03-27T07:55:47.378571Z",
     "shell.execute_reply": "2025-03-27T07:55:47.377754Z",
     "shell.execute_reply.started": "2025-03-27T07:55:47.364610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, model_code, num_rows=2):\n",
    "    print(\"\\nEvaluating on Test Set...\")\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    sample_images = []\n",
    "    sample_heatmaps = []\n",
    "    sample_labels = []\n",
    "    sample_preds = []\n",
    "    sample_confidences = []\n",
    "\n",
    "    num_examples = num_rows * 5\n",
    "    \n",
    "    # Identify the last convolutional layer\n",
    "    if model_code == \"densenet121\":\n",
    "        last_conv_layer = model.features.denseblock4.denselayer16.conv2\n",
    "    elif model_code == \"densenet169\":\n",
    "        last_conv_layer = model.features.denseblock4.denselayer32.conv2\n",
    "    # Register hooks for Grad-CAM\n",
    "    last_conv_layer.register_full_backward_hook(backward_hook)\n",
    "    last_conv_layer.register_forward_hook(forward_hook)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, desc=\"Testing\", total=num_batches, leave=True):\n",
    "            X, y = X.to(device), y.to(device).view(-1, 1).float()\n",
    "            pred = model(X)\n",
    "            prob = pred.sigmoid()\n",
    "            pred_labels = (prob > 0.5).float()\n",
    "\n",
    "            correct += (pred_labels == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_preds.extend(pred_labels.cpu().numpy())\n",
    "            all_probs.extend(prob.cpu().numpy())\n",
    "\n",
    "            # Store sample images and Grad-CAM visualizations\n",
    "            if len(sample_images) < num_examples:\n",
    "                for i in range(min(num_examples - len(sample_images), X.shape[0])): \n",
    "                    img_tensor = X[i].cpu()\n",
    "                    # Enable gradients only for Grad-CAM\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        heatmap = generate_gradcam(model, X[i].unsqueeze(0))\n",
    "\n",
    "                    original_img, overlay_img = overlay_heatmap(img_tensor, heatmap)\n",
    "\n",
    "                    sample_images.append(original_img)\n",
    "                    sample_heatmaps.append(overlay_img)\n",
    "                    sample_labels.append(int(y[i].cpu().item()))\n",
    "                    sample_preds.append(int(pred_labels[i].cpu().item()))\n",
    "\n",
    "                    # Compute adjusted confidence score\n",
    "                    prob_value = prob[i].cpu().item()\n",
    "                    if pred_labels[i] == 1:\n",
    "                        confidence = (prob_value - 0.5) * 200\n",
    "                    else:\n",
    "                        confidence = (0.5 - prob_value) * 200\n",
    "\n",
    "                    sample_confidences.append(confidence)\n",
    "\n",
    "    # Compute final metrics\n",
    "    accuracy = correct / total * 100\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC: {auc:.3f}\")\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Benign\", \"Malignant\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot original images and Grad-CAM heatmaps\n",
    "    fig, axes = plt.subplots(num_rows * 2, 5, figsize=(15, 6 * num_rows))\n",
    "    fig.suptitle(\"Sample Predictions with Grad-CAM\", fontsize=16)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        row = (i // 5) * 2\n",
    "        col = i % 5\n",
    "\n",
    "        # Plot original image\n",
    "        axes[row, col].imshow(sample_images[i], cmap=\"gray\")\n",
    "        true_label = \"Malignant\" if sample_labels[i] == 1 else \"Benign\"\n",
    "        pred_label = \"Malignant\" if sample_preds[i] == 1 else \"Benign\"\n",
    "        confidence = sample_confidences[i]\n",
    "\n",
    "        axes[row, col].set_title(f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%\")\n",
    "        axes[row, col].axis(\"off\")\n",
    "\n",
    "        # Plot Grad-CAM heatmap\n",
    "        axes[row + 1, col].imshow(sample_images[i], cmap=\"gray\")\n",
    "        axes[row + 1, col].imshow(sample_heatmaps[i], alpha=0.4, interpolation=\"nearest\")\n",
    "        axes[row + 1, col].set_title(\"Grad-CAM\")\n",
    "        axes[row + 1, col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:52.960421Z",
     "iopub.status.busy": "2025-03-27T07:55:52.960142Z",
     "iopub.status.idle": "2025-03-27T07:55:52.966403Z",
     "shell.execute_reply": "2025-03-27T07:55:52.965555Z",
     "shell.execute_reply.started": "2025-03-27T07:55:52.960401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Current Device:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:53.415918Z",
     "iopub.status.busy": "2025-03-27T07:55:53.415631Z",
     "iopub.status.idle": "2025-03-27T07:55:53.419905Z",
     "shell.execute_reply": "2025-03-27T07:55:53.418969Z",
     "shell.execute_reply.started": "2025-03-27T07:55:53.415894Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True  # Optimizes for fixed-size inputs\n",
    "torch.backends.cudnn.enabled = True    # Ensures CUDA is used efficiently\n",
    "#torch.set_num_threads(1)  # Prevents PyTorch from using CPU threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T07:55:53.857866Z",
     "iopub.status.busy": "2025-03-27T07:55:53.857565Z",
     "iopub.status.idle": "2025-03-27T07:55:54.087406Z",
     "shell.execute_reply": "2025-03-27T07:55:54.086651Z",
     "shell.execute_reply.started": "2025-03-27T07:55:53.857841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # Frees unused memory\n",
    "torch.cuda.ipc_collect()  # Helps free memory from inter-process communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet-169 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:42:37.343605Z",
     "iopub.status.busy": "2025-03-27T10:42:37.343303Z",
     "iopub.status.idle": "2025-03-27T10:42:37.711913Z",
     "shell.execute_reply": "2025-03-27T10:42:37.711182Z",
     "shell.execute_reply.started": "2025-03-27T10:42:37.343579Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Training DenseNet169\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from torchvision.models import densenet169, DenseNet169_Weights\n",
    "\n",
    "# Using pretrained DenseNet-169\n",
    "model_d169 = densenet169(weights=DenseNet169_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "model_d169.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1664, out_features=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 5e-4\n",
    "epochs = 10\n",
    "\n",
    "# Define loss function and optimizer with weight decay\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_d169.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_d169 = model_d169.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T10:42:37.935037Z",
     "iopub.status.busy": "2025-03-27T10:42:37.934794Z",
     "iopub.status.idle": "2025-03-27T11:19:48.057034Z",
     "shell.execute_reply": "2025-03-27T11:19:48.056041Z",
     "shell.execute_reply.started": "2025-03-27T10:42:37.935018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize tracking lists\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "val_aucs = []\n",
    "\n",
    "# Training loop with validation\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "# Define path to save the best model\n",
    "best_model_path = \"best_model_d169.pth\"\n",
    "\n",
    "# Initialize variables to track best model\n",
    "best_val_loss, best_val_auc = float(\"inf\"), 0.0\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    train_loss, train_accuracy = train(train_dataloader, model_d169, loss_fn, optimizer)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1, val_auc = val(val_dataloader, model_d169, loss_fn)\n",
    "    \n",
    "    \n",
    "    # Store metrics for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_precisions.append(val_prec)\n",
    "    val_recalls.append(val_rec)\n",
    "    val_f1s.append(val_f1)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    # Early stopping and best model saving\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model_d169.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with loss: {val_loss:.4f}, accuracy: {val_acc:.2f}%, AUC: {val_auc:.2f}\\n\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {t+1}\")\n",
    "        break\n",
    "\n",
    "    # Step the scheduler at the end of the epoch\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {t+1} completed, LR: {scheduler.get_last_lr()}\")\n",
    "\n",
    "print(\"Training Done!\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\", marker=\"o\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T11:24:47.339310Z",
     "iopub.status.busy": "2025-03-27T11:24:47.338905Z",
     "iopub.status.idle": "2025-03-27T11:25:55.838181Z",
     "shell.execute_reply": "2025-03-27T11:25:55.837227Z",
     "shell.execute_reply.started": "2025-03-27T11:24:47.339272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the best model state\n",
    "best_model_path = \"/kaggle/working/best_model_d169.pth\"\n",
    "\n",
    "best_model = densenet169(weights=None)\n",
    "# Modify the classifier for binary classification\n",
    "best_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1664, out_features=1)\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "best_model.eval()\n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = test(test_dataloader, best_model, model_code=\"densenet169\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet-121 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T14:47:25.317705Z",
     "iopub.status.busy": "2025-03-27T14:47:25.317334Z",
     "iopub.status.idle": "2025-03-27T14:47:25.549896Z",
     "shell.execute_reply": "2025-03-27T14:47:25.549118Z",
     "shell.execute_reply.started": "2025-03-27T14:47:25.317670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# training DenseNet121\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "# Using pretrained DenseNet-121\n",
    "model_d121 = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "model_d121.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1024, out_features=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "# Define loss function and optimizer with weight decay\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_d121.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_d121 = model_d121.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T14:47:27.700149Z",
     "iopub.status.busy": "2025-03-27T14:47:27.699769Z",
     "iopub.status.idle": "2025-03-27T15:14:15.707315Z",
     "shell.execute_reply": "2025-03-27T15:14:15.706313Z",
     "shell.execute_reply.started": "2025-03-27T14:47:27.700086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize tracking lists\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "val_aucs = []\n",
    "\n",
    "# Training loop with validation\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "# Define path to save the best model\n",
    "best_model_path = \"best_model_d121.pth\"\n",
    "\n",
    "# Initialise variables to track best model\n",
    "best_val_loss, best_val_auc = float(\"inf\"), 0.0\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    train_loss, train_accuracy = train(train_dataloader, model_d121, loss_fn, optimizer)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1, val_auc = val(val_dataloader, model_d121, loss_fn)\n",
    "    \n",
    "    \n",
    "    # Store metrics for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_precisions.append(val_prec)\n",
    "    val_recalls.append(val_rec)\n",
    "    val_f1s.append(val_f1)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    # Early stopping and best model saving\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model_d121.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with loss: {val_loss:.4f}, accuracy: {val_acc:.2f}%, AUC: {val_auc:.2f}\\n\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {t+1}\")\n",
    "        break\n",
    "\n",
    "    # Step the scheduler at the end of the epoch\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {t+1} completed, LR: {scheduler.get_last_lr()}\")\n",
    "\n",
    "print(\"Training Done!\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\", marker=\"o\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T15:14:15.708890Z",
     "iopub.status.busy": "2025-03-27T15:14:15.708645Z",
     "iopub.status.idle": "2025-03-27T15:15:27.662126Z",
     "shell.execute_reply": "2025-03-27T15:15:27.661191Z",
     "shell.execute_reply.started": "2025-03-27T15:14:15.708867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the best model state\n",
    "best_model_path = \"/kaggle/working/best_model_d121.pth\"\n",
    "\n",
    "best_model = densenet121(weights=None)\n",
    "# Modify the classifier for binary classification\n",
    "best_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1024, out_features=1)\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "best_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = test(test_dataloader, best_model, model_code=\"densenet121\", num_rows=3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6666901,
     "sourceId": 10749624,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6916193,
     "sourceId": 11094768,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
