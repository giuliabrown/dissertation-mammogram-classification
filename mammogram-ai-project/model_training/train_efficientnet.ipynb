{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B0 Training\n",
    "\n",
    "This notebook trains one convolutional neural network architecture, **EfficientNet-B0**, for binary classification of mammograms (benign vs malignant).\n",
    "\n",
    "The training was performed on **Kaggle** using GPU acceleration.  \n",
    "If you wish to run this notebook locally, you may need to modify some directory paths (e.g., for data loading, model saving, and output locations) to match your machine's folder structure.\n",
    "\n",
    "Key components of this notebook include:\n",
    "- Loading and preprocessing the training and validation datasets\n",
    "- Applying data augmentation to improve model generalisation\n",
    "- Fine-tuning EfficientNet-B0 model pre-trained on ImageNet\n",
    "- Tracking training and validation performance over epochs\n",
    "- Saving the best-performing model checkpoints based on accuracy and validation AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:41.159120Z",
     "iopub.status.busy": "2025-04-19T12:21:41.158843Z",
     "iopub.status.idle": "2025-04-19T12:21:48.277767Z",
     "shell.execute_reply": "2025-04-19T12:21:48.276879Z",
     "shell.execute_reply.started": "2025-04-19T12:21:41.159098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, random_split, ConcatDataset, Subset, DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:48.279056Z",
     "iopub.status.busy": "2025-04-19T12:21:48.278714Z",
     "iopub.status.idle": "2025-04-19T12:21:48.284549Z",
     "shell.execute_reply": "2025-04-19T12:21:48.283607Z",
     "shell.execute_reply.started": "2025-04-19T12:21:48.279034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image_rgb = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image_rgb = self.transform(image_rgb)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image_rgb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:48.286859Z",
     "iopub.status.busy": "2025-04-19T12:21:48.286498Z",
     "iopub.status.idle": "2025-04-19T12:21:48.406369Z",
     "shell.execute_reply": "2025-04-19T12:21:48.405590Z",
     "shell.execute_reply.started": "2025-04-19T12:21:48.286826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to add Gaussian noise\n",
    "class AddGaussianNoise(torch.nn.Module):\n",
    "    def __init__(self, mean=0.0, std=0.05, p=0.3):\n",
    "        super().__init__()\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        if random.random() < self.p:  \n",
    "            noise = torch.randn_like(tensor) * self.std\n",
    "            tensor = torch.clamp(tensor + noise, 0, 1) \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:48.407909Z",
     "iopub.status.busy": "2025-04-19T12:21:48.407622Z",
     "iopub.status.idle": "2025-04-19T12:21:48.419590Z",
     "shell.execute_reply": "2025-04-19T12:21:48.418825Z",
     "shell.execute_reply.started": "2025-04-19T12:21:48.407888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom CLAHE Transform\n",
    "class ApplyCLAHE:\n",
    "    def __init__(self, clip_limit=5.0, tile_grid_size=(8,8), p=1.0):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "        self.p = p \n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p: \n",
    "            img_np = np.array(img)\n",
    "            img_gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "            clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "            img_clahe = clahe.apply(img_gray)\n",
    "\n",
    "            # Convert back to 3-channel grayscale (DenseNet expects 3 channels)\n",
    "            img_clahe = cv2.merge([img_clahe, img_clahe, img_clahe])\n",
    "            return Image.fromarray(img_clahe)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:48.436158Z",
     "iopub.status.busy": "2025-04-19T12:21:48.435862Z",
     "iopub.status.idle": "2025-04-19T12:21:48.443523Z",
     "shell.execute_reply": "2025-04-19T12:21:48.442764Z",
     "shell.execute_reply.started": "2025-04-19T12:21:48.436132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# define transformations to apply to the images (for ImageNet weights)\n",
    "train_transform  = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    #ApplyCLAHE(clip_limit=5.0, tile_grid_size=(8,8), p=1.0),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1), \n",
    "    T.ToTensor(),\n",
    "    AddGaussianNoise(std=0.05, p=0.3),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform  = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    #ApplyCLAHE(clip_limit=5.0, tile_grid_size=(8,8), p=1.0),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:48.444522Z",
     "iopub.status.busy": "2025-04-19T12:21:48.444279Z",
     "iopub.status.idle": "2025-04-19T12:21:48.495354Z",
     "shell.execute_reply": "2025-04-19T12:21:48.494794Z",
     "shell.execute_reply.started": "2025-04-19T12:21:48.444494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define paths to cropped calcification data\n",
    "calc_train_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Training-png-cropped/labels/calc-train_labels.csv\"\n",
    "calc_test_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Test-png-cropped/labels/calc-test_labels.csv\"\n",
    "\n",
    "calc_train_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Training-png-cropped/images\"\n",
    "calc_test_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Calc-Test-png-cropped/images\"\n",
    "\n",
    "# Apply the transformations to the calcification images\n",
    "calc_training_data = CustomImageDataset(calc_train_label_dir, calc_train_img_dir, train_transform)\n",
    "calc_test_data = CustomImageDataset(calc_test_label_dir, calc_test_img_dir, test_transform)\n",
    "\n",
    "# Define paths to cropped mass data\n",
    "mass_train_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Training-png-cropped/labels/mass-train_labels.csv\"\n",
    "mass_test_label_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Test-png-cropped/labels/mass-test_labels.csv\"\n",
    "\n",
    "mass_train_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Training-png-cropped/images\"\n",
    "mass_test_img_dir = \"/Users/giulia/Desktop/dissertation-mammogram-classification/mammogram-ai-project/Data/Data png cropped/Mass-Test-png-cropped/images\"\n",
    "\n",
    "# Apply the transformations to the mass images\n",
    "mass_training_data = CustomImageDataset(mass_train_label_dir, mass_train_img_dir, train_transform)\n",
    "mass_test_data = CustomImageDataset(mass_test_label_dir, mass_test_img_dir, test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:48.496980Z",
     "iopub.status.busy": "2025-04-19T12:21:48.496792Z",
     "iopub.status.idle": "2025-04-19T12:21:48.500550Z",
     "shell.execute_reply": "2025-04-19T12:21:48.499649Z",
     "shell.execute_reply.started": "2025-04-19T12:21:48.496963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Merge training datasets\n",
    "combined_train_data = ConcatDataset([calc_training_data, mass_training_data])\n",
    "\n",
    "# Merge test datasets\n",
    "combined_test_data = ConcatDataset([calc_test_data, mass_test_data])\n",
    "\n",
    "# Split training data into train and validation (maintaining the labels balanced in both datasets)\n",
    "# Define validation split sizes (80% train, 20% validation)\n",
    "val_size = 0.2\n",
    "\n",
    "# Extract labels\n",
    "labels = []\n",
    "for dataset in combined_train_data.datasets:\n",
    "    labels.extend(dataset.img_labels.iloc[:, 2].tolist())\n",
    "\n",
    "# Perform stratified split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(combined_train_data)), \n",
    "    test_size = val_size, \n",
    "    stratify = labels,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(combined_train_data, train_idx)\n",
    "val_dataset = Subset(combined_train_data, val_idx)\n",
    "\n",
    "# Shuffle validation and testing datasets once before creating the dataloaders\n",
    "# Create shuffled indices\n",
    "val_indices = np.random.permutation(len(val_dataset))\n",
    "test_indices = np.random.permutation(len(combined_test_data))\n",
    "\n",
    "# Apply shuffled indices to dataset\n",
    "shuffled_val_data = Subset(val_dataset, val_indices)\n",
    "shuffled_test_data = Subset(combined_test_data, test_indices)\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(shuffled_val_data)}\")\n",
    "print(f\"Total testing samples: {len(shuffled_test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:48.734146Z",
     "iopub.status.busy": "2025-04-19T12:21:48.733938Z",
     "iopub.status.idle": "2025-04-19T12:21:48.738281Z",
     "shell.execute_reply": "2025-04-19T12:21:48.737439Z",
     "shell.execute_reply.started": "2025-04-19T12:21:48.734128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "# shuffle = True\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "# shuffle = False, so that the batches don't change every epoch, making it easier to compare results\n",
    "val_dataloader = DataLoader(shuffled_val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(shuffled_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:21:50.160233Z",
     "iopub.status.busy": "2025-04-19T12:21:50.159914Z",
     "iopub.status.idle": "2025-04-19T12:21:53.595556Z",
     "shell.execute_reply": "2025-04-19T12:21:53.594683Z",
     "shell.execute_reply.started": "2025-04-19T12:21:50.160204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"Benign\",\n",
    "    1: \"Malignant\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "\n",
    "    image_np = np.array(img)\n",
    "    print(image_np.shape)\n",
    "\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if(torch.is_tensor(img)):\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:22:08.152963Z",
     "iopub.status.busy": "2025-04-19T12:22:08.152563Z",
     "iopub.status.idle": "2025-04-19T12:22:08.159529Z",
     "shell.execute_reply": "2025-04-19T12:22:08.158646Z",
     "shell.execute_reply.started": "2025-04-19T12:22:08.152931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch, (X, y) in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Training\", leave=True):\n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True).view(-1, 1).float()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item() \n",
    "\n",
    "        # Calculate accuracy\n",
    "        pred_labels = (pred.sigmoid() > 0.5).float()\n",
    "        correct_predictions += (pred_labels == y).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # Calculate overall training accuracy\n",
    "    epoch_accuracy = correct_predictions / size * 100\n",
    "    \n",
    "    # You can calculate and store the average loss at the end of each epoch\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:22:08.448177Z",
     "iopub.status.busy": "2025-04-19T12:22:08.447908Z",
     "iopub.status.idle": "2025-04-19T12:22:08.455023Z",
     "shell.execute_reply": "2025-04-19T12:22:08.454111Z",
     "shell.execute_reply.started": "2025-04-19T12:22:08.448154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "def val(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = [] \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, desc=\"Testing\", total=num_batches, leave=True):\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True).view(-1, 1).float()\n",
    "            pred = model(X)\n",
    "            prob = pred.sigmoid()  # Convert logits to probabilities\n",
    "            pred_labels = (prob > 0.5).float()  # Convert probabilities to binary labels\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred_labels == y).sum().item()\n",
    "            \n",
    "            all_labels.extend(y.cpu().numpy())  # Collect true labels\n",
    "            all_preds.extend(pred_labels.cpu().numpy())  # Collect predicted labels\n",
    "            all_probs.extend(prob.cpu().numpy())  # Collect predicted probabilities\n",
    "\n",
    "    # Compute overall statistics\n",
    "    test_loss /= num_batches\n",
    "    accuracy = correct / size * 100\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {accuracy:.1f}%, Avg loss: {test_loss:.6f}\")\n",
    "    print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC: {auc:.3f}\\n\")\n",
    "\n",
    "    return test_loss, accuracy, precision, recall, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:22:08.800008Z",
     "iopub.status.busy": "2025-04-19T12:22:08.799719Z",
     "iopub.status.idle": "2025-04-19T12:22:08.808378Z",
     "shell.execute_reply": "2025-04-19T12:22:08.807467Z",
     "shell.execute_reply.started": "2025-04-19T12:22:08.799982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define global variables for Grad-CAM\n",
    "gradients = None\n",
    "activations = None\n",
    "\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    global gradients\n",
    "    gradients = grad_output\n",
    "\n",
    "def forward_hook(module, args, output):\n",
    "    global activations\n",
    "    activations = output\n",
    "\n",
    "def generate_gradcam(model, image):\n",
    "    \"\"\"\n",
    "    Generates Grad-CAM heatmap for a given image.\n",
    "    \"\"\"\n",
    "    global gradients, activations\n",
    "    \n",
    "    model.zero_grad()\n",
    "    output = model(image)\n",
    "    prob = output.sigmoid()\n",
    "    pred_label = (prob > 0.5).float()\n",
    "    \n",
    "    # Backward pass to get gradients\n",
    "    output.backward(torch.ones_like(output))  \n",
    "    \n",
    "    # Pool gradients across the channels\n",
    "    pooled_gradients = torch.mean(gradients[0], dim=[0, 2, 3])\n",
    "\n",
    "    # Weight the channels by corresponding gradients\n",
    "    for i in range(activations.size()[1]):\n",
    "        activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    # Compute heatmap\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = F.relu(heatmap)\n",
    "    heatmap /= torch.max(heatmap)\n",
    "\n",
    "    return heatmap.detach().cpu()\n",
    "\n",
    "def overlay_heatmap(img_tensor, heatmap):\n",
    "    \"\"\"\n",
    "    Overlays the Grad-CAM heatmap on the original image.\n",
    "    \"\"\"\n",
    "\n",
    "    unnorm_img = unnormalize(img_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    original_img = to_pil_image(unnorm_img.clamp(0, 1), mode='RGB')\n",
    "\n",
    "    # Resize the heatmap to match image size\n",
    "    overlay = to_pil_image(heatmap, mode='F').resize((224, 224), resample=PIL.Image.BICUBIC)\n",
    "\n",
    "    # Apply colormap\n",
    "    cmap = colormaps['jet']\n",
    "    overlay = (255 * cmap(np.asarray(overlay) ** 2)[:, :, :3]).astype(np.uint8)\n",
    "\n",
    "    return original_img, overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unnormalise images\n",
    "def unnormalise(img_tensor, mean, std):\n",
    "    mean = torch.tensor(mean).view(3, 1, 1)\n",
    "    std = torch.tensor(std).view(3, 1, 1)\n",
    "    return img_tensor * std + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:22:10.118919Z",
     "iopub.status.busy": "2025-04-19T12:22:10.118529Z",
     "iopub.status.idle": "2025-04-19T12:22:10.136545Z",
     "shell.execute_reply": "2025-04-19T12:22:10.135792Z",
     "shell.execute_reply.started": "2025-04-19T12:22:10.118889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, model_code, num_rows=2):\n",
    "    print(\"\\nEvaluating on Test Set...\")\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    sample_images = []\n",
    "    sample_heatmaps = []\n",
    "    sample_labels = []\n",
    "    sample_preds = []\n",
    "    sample_confidences = []\n",
    "\n",
    "    num_examples = num_rows * 5\n",
    "    \n",
    "    # Identify the last convolutional layer\n",
    "    if model_code == \"densenet121\":\n",
    "        last_conv_layer = model.features.denseblock4.denselayer16.conv2\n",
    "    elif model_code == \"densenet169\":\n",
    "        last_conv_layer = model.features.denseblock4.denselayer32.conv2\n",
    "    # Register hooks for Grad-CAM\n",
    "    last_conv_layer.register_full_backward_hook(backward_hook)\n",
    "    last_conv_layer.register_forward_hook(forward_hook)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(dataloader, desc=\"Testing\", total=num_batches, leave=True):\n",
    "            X, y = X.to(device), y.to(device).view(-1, 1).float()\n",
    "            pred = model(X)\n",
    "            prob = pred.sigmoid()\n",
    "            pred_labels = (prob > 0.5).float()\n",
    "\n",
    "            correct += (pred_labels == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_preds.extend(pred_labels.cpu().numpy())\n",
    "            all_probs.extend(prob.cpu().numpy())\n",
    "\n",
    "            # Store sample images and Grad-CAM visualizations\n",
    "            if len(sample_images) < num_examples:\n",
    "                for i in range(min(num_examples - len(sample_images), X.shape[0])): \n",
    "                    img_tensor = X[i].cpu()\n",
    "                    # Enable gradients only for Grad-CAM\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        heatmap = generate_gradcam(model, X[i].unsqueeze(0))\n",
    "\n",
    "                    original_img, overlay_img = overlay_heatmap(img_tensor, heatmap)\n",
    "\n",
    "                    sample_images.append(original_img)\n",
    "                    sample_heatmaps.append(overlay_img)\n",
    "                    sample_labels.append(int(y[i].cpu().item()))\n",
    "                    sample_preds.append(int(pred_labels[i].cpu().item()))\n",
    "\n",
    "                    # Compute adjusted confidence score\n",
    "                    prob_value = prob[i].cpu().item()\n",
    "                    if pred_labels[i] == 1:\n",
    "                        confidence = (prob_value - 0.5) * 200\n",
    "                    else:\n",
    "                        confidence = (0.5 - prob_value) * 200\n",
    "\n",
    "                    sample_confidences.append(confidence)\n",
    "\n",
    "    # Compute final metrics\n",
    "    accuracy = correct / total * 100\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1:.3f}, AUC: {auc:.3f}\")\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Benign\", \"Malignant\"])\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot original images and Grad-CAM heatmaps\n",
    "    fig, axes = plt.subplots(num_rows * 2, 5, figsize=(15, 6 * num_rows))\n",
    "    fig.suptitle(\"Sample Predictions with Grad-CAM\", fontsize=16)\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        row = (i // 5) * 2\n",
    "        col = i % 5\n",
    "\n",
    "        # Plot original image\n",
    "        axes[row, col].imshow(sample_images[i], cmap=\"gray\")\n",
    "        true_label = \"Malignant\" if sample_labels[i] == 1 else \"Benign\"\n",
    "        pred_label = \"Malignant\" if sample_preds[i] == 1 else \"Benign\"\n",
    "        confidence = sample_confidences[i]\n",
    "\n",
    "        axes[row, col].set_title(f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%\")\n",
    "        axes[row, col].axis(\"off\")\n",
    "\n",
    "        # Plot Grad-CAM heatmap\n",
    "        axes[row + 1, col].imshow(sample_images[i], cmap=\"gray\")\n",
    "        axes[row + 1, col].imshow(sample_heatmaps[i], alpha=0.4, interpolation=\"nearest\")\n",
    "        axes[row + 1, col].set_title(\"Grad-CAM\")\n",
    "        axes[row + 1, col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:22:13.228142Z",
     "iopub.status.busy": "2025-04-19T12:22:13.227814Z",
     "iopub.status.idle": "2025-04-19T12:22:13.345386Z",
     "shell.execute_reply": "2025-04-19T12:22:13.344589Z",
     "shell.execute_reply.started": "2025-04-19T12:22:13.228114Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: Tesla T4\n",
      "Current Device: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Current Device:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:22:13.470961Z",
     "iopub.status.busy": "2025-04-19T12:22:13.470659Z",
     "iopub.status.idle": "2025-04-19T12:22:13.474826Z",
     "shell.execute_reply": "2025-04-19T12:22:13.473955Z",
     "shell.execute_reply.started": "2025-04-19T12:22:13.470937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True\n",
    "#torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T12:22:14.485370Z",
     "iopub.status.busy": "2025-04-19T12:22:14.485079Z",
     "iopub.status.idle": "2025-04-19T12:22:14.489173Z",
     "shell.execute_reply": "2025-04-19T12:22:14.488263Z",
     "shell.execute_reply.started": "2025-04-19T12:22:14.485348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:21:55.691079Z",
     "iopub.status.busy": "2025-04-19T13:21:55.690721Z",
     "iopub.status.idle": "2025-04-19T13:21:55.854517Z",
     "shell.execute_reply": "2025-04-19T13:21:55.853643Z",
     "shell.execute_reply.started": "2025-04-19T13:21:55.691051Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR \n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "# Using pretrained EfficientNet-B0\n",
    "model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1) \n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=1280, out_features=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 1e-4\n",
    "epochs = 10\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(device)\n",
    "\n",
    "# Define loss function and optimiser\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.7], device=device))  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  \n",
    "\n",
    "# Define learning rate scheduler\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:22:00.392941Z",
     "iopub.status.busy": "2025-04-19T13:22:00.392498Z",
     "iopub.status.idle": "2025-04-19T13:45:39.020716Z",
     "shell.execute_reply": "2025-04-19T13:45:39.019449Z",
     "shell.execute_reply.started": "2025-04-19T13:22:00.392900Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize tracking lists\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "val_aucs = []\n",
    "\n",
    "# Training loop with validation\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "# Define path to save the best model\n",
    "best_model_path = \"best_model_eb0.pth\"\n",
    "\n",
    "# Initialize variables to track best model\n",
    "best_val_loss, best_val_auc = float(\"inf\"), 0.0\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"\\nEpoch {t+1}\\n-------------------------------\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_accuracy = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1, val_auc = val(val_dataloader, model, loss_fn)\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_duration = end_time - start_time\n",
    "    epoch_minutes = epoch_duration / 60\n",
    "    print(f\"Epoch {t+1} took {epoch_minutes:.2f} minutes\")\n",
    "    \n",
    "    # Store metrics for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_precisions.append(val_prec)\n",
    "    val_recalls.append(val_rec)\n",
    "    val_f1s.append(val_f1)\n",
    "    val_aucs.append(val_auc)\n",
    "\n",
    "    # Early stopping and best model saving\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with loss: {val_loss:.4f}, accuracy: {val_acc:.2f}%, AUC: {val_auc:.2f}\\n\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {t+1}\")\n",
    "        break\n",
    "\n",
    "    # Step the scheduler at the end of the epoch\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {t+1} completed, LR: {scheduler.get_last_lr()}\")\n",
    "\n",
    "print(\"Training Done!\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\", marker=\"o\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\", marker=\"o\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T13:46:44.622255Z",
     "iopub.status.busy": "2025-04-19T13:46:44.621888Z",
     "iopub.status.idle": "2025-04-19T13:48:17.536513Z",
     "shell.execute_reply": "2025-04-19T13:48:17.534943Z",
     "shell.execute_reply.started": "2025-04-19T13:46:44.622227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the best model state\n",
    "best_model_path = \"best_model_eb0.pth\"\n",
    "\n",
    "# Using EfficientNet-B0\n",
    "best_model = efficientnet_b0(weights=None) \n",
    "\n",
    "# Modify the classifier for binary classification\n",
    "best_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_features=1280, out_features=1)\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, weights_only=True))\n",
    "best_model.eval()\n",
    "\n",
    "# Run final test\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = test(test_dataloader, best_model, model_code=\"efficientnetB0\", num_rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6916193,
     "sourceId": 11094768,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
